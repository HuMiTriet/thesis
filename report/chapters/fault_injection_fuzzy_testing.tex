\section{Fault Injection and Property Based Testing Phase}


\subsection{Property Based Testing}
Upon completing the implementation of the algorithms mentioned in \ref{chap:algorithms}, it was essential to verify their correctness. To accomplish this, we utilized a property-based testing framework called \textit{Hypothesis}.

However, before delving into Hypothesis, it's worth providing a brief historical overview of fuzzy testing. First introduced in \cite{OG_fuzzy_testing}, researchers used fuzzy testing to bombard Unix utilities like awk, grep, etc., with an abundance of random inputs to identify any instances of system crashes or undefined behavior.

Over time, fuzzy testing evolved and matured, leading to the development of a
more advanced technique known as property-based testing, exemplified by
\textit{Quickcheck} \cite{quickcheck}. This approach still involved generating
random input for the program under test, but instead of merely searching for
crashes, it tested whether certain properties or invariants are held throughout the runtime. Additionally, once an invariant was violated, it could be shrunk to a minimal failing example, which is the smallest test case that would produce the same behavior.

In this project, we used \textit{Hypothesis}, a Python implementation of \textit{Quickcheck}.
Hypothesis includes features in addition to those of Quickcheck, such as caching previous errors and stateful testing.

\subsubsection{Basic Hypothesis Tests}
\label{subsubsec:basic_hypothesis_tests}


\begin{listing}[!ht]
  \begin{minted}{python}
from hypothesis import given, strategies as st
@given(
    resource_id=st.sampled_from(["A", "B"]),
    client_port=st.integers(min_value=5002, max_value=5003),
)
  # ...
  \end{minted}
  \caption{Hypothesis python decorator}
  \label{code:hypothesis_decorator}
\end{listing}

The decorator shown in listing \ref{code:hypothesis_decorator} sets up the input randomization. This test case implies that a random client, from among the four clients, will attempt to lock either resource type "A" or "B".


\begin{listing}[!ht]
  \begin{minted}{python}
#...
def test_one_client_lock_and_delete(
    setup_ricart_agrawala, # pytest's fixture
    resource_id: str,
    client_port: int,
):
  #...
  \end{minted}
  \caption{Test case function signature}
  \label{code:test_case_signature}
\end{listing}

In the function signature for the test case, as shown in listing
\ref{code:test_case_signature}, the parameters \textit{resource\_id} and
\textit{client\_port} are provided by the Hypothesis decorator from listing \ref{code:hypothesis_decorator}. 
The parameter \textit{setup\_ricart\_agrawala} is a pytest fixture, which
prepares the clients, proxy, logger, and resource manager at the start and kill
all the processes at the 
conclusion of each test. This ensures a clean slate and a test environment unaffected by previous runs.


\begin{listing}[!ht]
  \begin{minted}{python}
    #...
    response = requests.post(
        f"http://127.0.0.1:{client_port}/{resource_id}/lock",
        timeout=TESTING_TIMEOUT,
    )

    assert response.status_code == 200

    response = requests.delete(
        f"http://127.0.0.1:{client_port}/{resource_id}/lock",
        timeout=TESTING_TIMEOUT,
    )

    assert response.status_code == 200
  \end{minted}
  \caption{Body of the test case}
  \label{code:test_case_body}
\end{listing}


The test logic shown in listing \ref{code:test_case_body} involves checking the request response's status code after each client locks or deletes a specific resource. This is done using Python's \textit{assert} to ensure the status code equals 200, indicating successful execution.

\subsubsection{Stateful Testing}
\label{subsubsec:stateful_testing}
In the previous section, as presented in listing \ref{subsubsec:basic_hypothesis_tests}, \textit{Hypothesis} only randomized the inputs for each test case. However, during the development of the prototype for this project, the majority of the bugs found were not a result of randomizing the inputs. Instead, they were due to the random ordering of clients locking or deleting a resource. This is where Stateful testing comes into play.

Stateful testing, also known as model-based testing, employs a state machine with a predefined set of \textit{@rules}. The state machine then attempts to discover the sequence of \textit{@rules} that will lead to a failure.

\begin{listing}[!ht]
  \begin{minted}{python}
class MutexLocking(RuleBasedStateMachine):
  #... 
    @initialize()
    def inject_fault(self):
        #...
  def teardown(self):
  #...
      requests.post(
          f"{SERVER_URL}reset",
          timeout=TESTING_TIMEOUT,
      )
 \end{minted}
 \caption{Initialization and teardown of the state machine}
 \label{code:init_teardown_state_machine}
\end{listing}

The code depicted in listing \ref{code:init_teardown_state_machine} performs some initialization tasks to set up the testing environment and executes a \textit{teardown} operation to reset it. This mirrors the functionality of the pytest's fixture presented in \ref{code:test_case_signature}.

\begin{listing}[!ht]
  \begin{minted}{python}
    @rule(
        resource_id=st.sampled_from(["A", "B"]),
        client_port=st.integers(min_value=5002, max_value=5005),
    )
    def test_lock(
        self,
        resource_id: str,
        client_port: int,
    ):
    # ...

    #... 
    def test_unlock(#...)
    #... 
  \end{minted}
  \caption{Rules for locking and unlocking resources}
  \label{code:rule}
\end{listing}

Each of the rules in listing \ref{code:rule} will be run in an arbitrary order by hypothesis.

\begin{listing}[!ht]
  \begin{minted}{python}
    @invariant()
    def test_no_race_condition(self):
        response = requests.get(
            f"{SERVER_URL}race",
            timeout=TESTING_TIMEOUT,
        )
        assert response.status_code == 200
  \end{minted}
  \caption{Invariant checking for race condition on the resource manager}
  \label{code:invariant}
\end{listing}

In the example provided in listing \ref{code:invariant}, we have set an
invariant named\\ \textit{test\_no\_race\_condition}. This invariant ensures that
no race condition ever occurs on the resource manager, as explained in
\ref{subsubsec:resource_manager}. The invariant is executed after each rule is
applied to verify whether the invariant condition has been violated.

